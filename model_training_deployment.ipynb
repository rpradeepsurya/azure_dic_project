{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip show xgboost"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: xgboost\r\nVersion: 1.3.3\r\nSummary: XGBoost Python Package\r\nHome-page: https://github.com/dmlc/xgboost\r\nAuthor: None\r\nAuthor-email: None\r\nLicense: Apache-2.0\r\nLocation: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\nRequires: numpy, scipy\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1683353714151
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AML workspace details\r\n",
        "subscription_id = \"13457d73-d2df-4297-b63a-2632b1c1b881\"\r\n",
        "resource_group = \"rg-dic\"\r\n",
        "workspace = \"mlw-dic\"\r\n",
        "\r\n",
        "from azure.ai.ml import MLClient\r\n",
        "from azure.identity import DefaultAzureCredential\r\n",
        "\r\n",
        "# get a handle to the workspace\r\n",
        "ml_client = MLClient(\r\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class FeatureStoreOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass FeatureSetOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass FeatureStoreEntityOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683341762749
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Data Asset\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "my_path = './azure_dic_project/cleaned_data.csv'\r\n",
        "\r\n",
        "my_data = Data(\r\n",
        "    path=my_path,\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"Credit score brackets - Multi class classification dataset, cleaned\",\r\n",
        "    name=\"credit-score-data-cleaned\"\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading cleaned_data.csv\u001b[32m (< 1 MB): 100%|██████████| 22.8M/22.8M [00:00<00:00, 49.8MB/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'credit-score-data-cleaned', 'description': 'Credit score brackets - Multi class classification dataset, cleaned', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/13457d73-d2df-4297-b63a-2632b1c1b881/resourceGroups/rg-dic/providers/Microsoft.MachineLearningServices/workspaces/mlw-dic/data/credit-score-data-cleaned/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/dic-compute/code/Users/pradeepsurya', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f3da4a7f7f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f3d92672fe0>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/13457d73-d2df-4297-b63a-2632b1c1b881/resourcegroups/rg-dic/workspaces/mlw-dic/datastores/workspaceblobstore/paths/LocalUpload/328d7d28beaabebf66e7237ba87a940e/cleaned_data.csv', 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683324160979
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ml_client.data.list()\r\n",
        "for ds_name in datasets:\r\n",
        "    print(ds_name.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "credit-score-data-cleaned\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683352086155
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Script"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "# create a folder for the script files\r\n",
        "script_folder = 'src'\r\n",
        "os.makedirs(script_folder, exist_ok=True)\r\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683347576774
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train-model-mlflow.py\r\n",
        "# import libraries\r\n",
        "import mlflow\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "import xgboost as xgb\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    # enable autologging\r\n",
        "    mlflow.autolog()\r\n",
        "    \r\n",
        "    # Read data asset\r\n",
        "    print(\"Reading data...\")\r\n",
        "    df = pd.read_csv(args.training_data)\r\n",
        "\r\n",
        "    # Read model hyperparameters from json file\r\n",
        "    with open(args.hparam_file) as f:\r\n",
        "        hyperparameters = json.load(f)\r\n",
        "\r\n",
        "    # Label Encoding\r\n",
        "    le = LabelEncoder()\r\n",
        "    df['Month'] = le.fit_transform(df['Month'])\r\n",
        "\r\n",
        "    # One hot encoding\r\n",
        "    encoded_df = pd.get_dummies(df, columns=['Occupation', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour'])\r\n",
        "    \r\n",
        "    # Scaling numerical features\r\n",
        "    scaler = MinMaxScaler()\r\n",
        "    cols = ['Month','Age','Annual_Income','Monthly_Inhand_Salary','Num_Bank_Accounts','Num_Credit_Card','Interest_Rate',\r\n",
        "        'Num_of_Loan', 'Delay_from_due_date','Num_of_Delayed_Payment','Changed_Credit_Limit','Num_Credit_Inquiries',\r\n",
        "        'Outstanding_Debt', 'Credit_Utilization_Ratio','Credit_History_Age','Total_EMI_per_month','Amount_invested_monthly']\r\n",
        "\r\n",
        "    encoded_df[cols] = scaler.fit_transform(encoded_df[cols])\r\n",
        "\r\n",
        "    # split data\r\n",
        "    print(\"Splitting data...\")\r\n",
        "    y = encoded_df['Credit_Score']\r\n",
        "    y = y.map({'Good':2, 'Standard':1, 'Poor':0})\r\n",
        "    X = encoded_df.drop(['Credit_Score'], axis=1)\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=587)\r\n",
        "\r\n",
        "    # train model\r\n",
        "    print(\"Training model...\")\r\n",
        "    model = xgb.XGBClassifier(**hyperparameters)\r\n",
        "    model.fit(X_train, y_train)\r\n",
        "\r\n",
        "    # evaluate model\r\n",
        "    y_hat = model.predict(X_test)\r\n",
        "    acc = np.average(y_hat == y_test)\r\n",
        "    print('Accuracy:', acc)\r\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\r\n",
        "\r\n",
        "    f1 = f1_score(y_test, y_hat, average='weighted')\r\n",
        "    print('F1 score:', f1)\r\n",
        "    mlflow.log_metric(\"F1-score\", f1)\r\n",
        "\r\n",
        "    y_scores = model.predict_proba(X_test)\r\n",
        "\r\n",
        "    # Feature importances\r\n",
        "    importances = model.feature_importances_\r\n",
        "    indices = np.argsort(importances)[::-1]\r\n",
        "    feature_names = X_train.columns\r\n",
        "\r\n",
        "    fig = plt.figure(figsize=(6, 4))\r\n",
        "    plt.bar(range(len(importances)), importances[indices], align='center')\r\n",
        "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation='vertical')\r\n",
        "    plt.xlabel('Features')\r\n",
        "    plt.ylabel('Importance')\r\n",
        "    plt.title('XGBoost Feature Importance')\r\n",
        "    plt.savefig(\"xgb_feature_importance.png\")\r\n",
        "    mlflow.log_artifact(\"xgb_feature_importance.png\") \r\n",
        "\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument(\"--training_data\", dest='training_data', type=str)\r\n",
        "    parser.add_argument(\"--json_file\", dest=\"hparam_file\", type=str, help=\"Path to the JSON file containing hyperparameters\")\r\n",
        "\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    print(\"\\n\\n\")\r\n",
        "    print(\"*\" * 60)\r\n",
        "\r\n",
        "    args = parse_args()\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-model-mlflow.py\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/dic-compute/code/Users/pradeepsurya\r\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\r\n",
        "from azure.ai.ml import Input\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "# configure input \r\n",
        "job_input = {\r\n",
        "    \"data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:credit-score-data-cleaned:1\")\r\n",
        "}\r\n",
        "\r\n",
        "# configure job\r\n",
        "job = command(\r\n",
        "    code=\"./src\",\r\n",
        "    command=\"python train-model-mlflow.py --training_data ${{inputs.data}} --json_file xgb_hyperparameters\",\r\n",
        "    inputs=job_input,\r\n",
        "    environment=\"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest\",\r\n",
        "    compute=\"anl-cluster\",\r\n",
        "    display_name=\"xgb-train-optimal\",\r\n",
        "    experiment_name=\"credit-score-xgb-mlflow\"\r\n",
        "    )\r\n",
        "\r\n",
        "# submit job\r\n",
        "returned_job = ml_client.create_or_update(job)\r\n",
        "aml_url = returned_job.studio_url\r\n",
        "print(\"Monitor job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading src (0.0 MBs): 100%|██████████| 3628/3628 [00:00<00:00, 48812.28it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor job at https://ml.azure.com/runs/happy_tooth_krzs2642pg?wsid=/subscriptions/13457d73-d2df-4297-b63a-2632b1c1b881/resourcegroups/rg-dic/workspaces/mlw-dic&tid=234a6691-d3c4-40e4-86a9-01996278dd47\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683355569803
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "job_name = returned_job.name\r\n",
        "\r\n",
        "run_model = Model(\r\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\r\n",
        "    name=\"mlflow-diabetes\",\r\n",
        "    description=\"Model created from run.\",\r\n",
        "    type=AssetTypes.MLFLOW_MODEL,\r\n",
        ")\r\n",
        "# Uncomment after adding required details above\r\n",
        "ml_client.models.create_or_update(run_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\r\n",
        "import datetime\r\n",
        "\r\n",
        "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\r\n",
        "\r\n",
        "# create an online endpoint\r\n",
        "endpoint = ManagedOnlineEndpoint(\r\n",
        "    name=online_endpoint_name,\r\n",
        "    description=\"Online endpoint for MLflow diabetes model\",\r\n",
        "    auth_mode=\"key\",\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Deployment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "# create a blue deployment\r\n",
        "model = Model(\r\n",
        "    path=\"./model\",\r\n",
        "    type=AssetTypes.MLFLOW_MODEL,\r\n",
        "    description=\"my sample mlflow model\",\r\n",
        ")\r\n",
        "\r\n",
        "blue_deployment = ManagedOnlineDeployment(\r\n",
        "    name=\"blue\",\r\n",
        "    endpoint_name=online_endpoint_name,\r\n",
        "    model=model,\r\n",
        "    instance_type=\"Standard_F4s_v2\",\r\n",
        "    instance_count=1,\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the details for online endpoint\r\n",
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\r\n",
        "\r\n",
        "# existing traffic details\r\n",
        "print(endpoint.traffic)\r\n",
        "\r\n",
        "# Get the scoring URI\r\n",
        "print(endpoint.scoring_uri)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}